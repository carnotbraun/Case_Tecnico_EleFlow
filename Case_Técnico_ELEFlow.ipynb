{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# BigData Airlines\n",
        "\n",
        "A Eleflow irá atender um novo cliente, a _BigData Airlines_, e você será o engenheiro de dados responsável por fazer a ingestão de dados e preparar algumas tabelas para os cientistas de dados e analistas de dados."
      ],
      "metadata": {
        "id": "0h6OwcRL3siV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção 0: Importar bibliotecas e configurar o ambiente"
      ],
      "metadata": {
        "id": "S_22FTwQbFnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importe as bibliotecas necessárias\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "# Configurar as chaves da API (se necessário)\n",
        "RAPIDAPI_KEY = \"https://rapidapi.com/Active-api/api/airport-info/\"\n"
      ],
      "metadata": {
        "id": "csQ3xhi0bJ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xQMR7MZAWxK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingestão de Dados"
      ],
      "metadata": {
        "id": "sulzJvo-37uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diretório dos arquivos JSON da pasta VRA\n",
        "vra_dir = '/content/drive/MyDrive/ELEFlow/VRA/'\n",
        "\n",
        "# Diretório dos arquivos CSV da pasta AIR_CIA\n",
        "air_cia_dir = '/content/drive/MyDrive/ELEFlow/AIR_CIA/'\n",
        "\n",
        "# Função para obter informações de aeródromos com base no código ICAO\n",
        "def get_aerodromo_info(icao_code):\n",
        "    api_url = f'https://rapidapi.com/Active-api/api/airport-info/{icao_code}'\n",
        "    headers = {\n",
        "        'X-RapidAPI-Host': 'active-api',\n",
        "        'X-RapidAPI-Key': 'your-api-key'  # Substitua pelo seu API Key\n",
        "    }\n",
        "\n",
        "    response = requests.get(api_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Carregar Dados de VRA\n",
        "\n",
        "# Lista para armazenar os DataFrames carregados dos arquivos JSON\n",
        "vra_dataframes = []\n",
        "\n",
        "# Percorra os arquivos JSON na pasta VRA e normalize os cabeçalhos\n",
        "for filename in os.listdir(vra_dir):\n",
        "    if filename.endswith(\".json\"):\n",
        "        file_path = os.path.join(vra_dir, filename)\n",
        "        df = pd.read_json(file_path)\n",
        "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "        vra_dataframes.append(df)\n",
        "\n",
        "# Concatene os DataFrames em um único DataFrame\n",
        "vra_combined = pd.concat(vra_dataframes, ignore_index=True)\n",
        "\n",
        "# Salve os dados em um formato adequado (por exemplo, CSV)\n",
        "vra_combined.to_csv('/content/drive/MyDrive/ELEFlow/vra_combined.csv', index=False)\n",
        "\n",
        "# Carregar Dados da Pasta AIR_CIA\n",
        "\n",
        "# Lista para armazenar os DataFrames carregados dos arquivos CSV\n",
        "air_cia_dataframes = []\n",
        "\n",
        "# Percorra os arquivos CSV na pasta AIR_CIA e normalize os cabeçalhos\n",
        "for filename in os.listdir(air_cia_dir):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(air_cia_dir, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "        # Divida a coluna 'ICAO IATA' em duas colunas\n",
        "        df[['ICAO', 'IATA']] = df['icao_iata'].str.split(expand=True)\n",
        "\n",
        "        air_cia_dataframes.append(df)\n",
        "\n",
        "# Concatene os DataFrames em um único DataFrame\n",
        "air_cia_combined = pd.concat(air_cia_dataframes, ignore_index=True)\n",
        "\n",
        "# Salve os dados em um formato adequado\n",
        "air_cia_combined.to_csv('/content/drive/MyDrive/ELEFlow/air_cia_combined.csv', index=False)"
      ],
      "metadata": {
        "id": "en-I6AWN4Dfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção 2: Criação de Tabelas de Aeródromos"
      ],
      "metadata": {
        "id": "rBwCP3Wj4FjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Tabela de Aeródromos\n",
        "\n",
        "# Crie um DataFrame vazio para armazenar os dados dos aeródromos\n",
        "aerodromos_df = pd.DataFrame(columns=['ICAO', 'Nome', 'Localizacao', 'Outras_Informacoes'])\n",
        "\n",
        "# Itere sobre os códigos ICAO dos dados VRA\n",
        "for icao_code in vra_combined['icao'].unique():\n",
        "    aerodromo_info = get_aerodromo_info(icao_code)\n",
        "    if aerodromo_info:\n",
        "        aerodromos_df = aerodromos_df.append({\n",
        "            'ICAO': icao_code,\n",
        "            'Nome': aerodromo_info['nome'],\n",
        "            'Localizacao': aerodromo_info['localizacao'],\n",
        "            'Outras_Informacoes': aerodromo_info['outras_informacoes']\n",
        "        }, ignore_index=True)\n",
        "\n",
        "# Salve os dados dos aeródromos em um formato adequado\n",
        "aerodromos_df.to_csv('/content/drive/MyDrive/ELEFlow/aerodromos.csv', index=False)"
      ],
      "metadata": {
        "id": "7ETALUzv2ZkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção 3: Criação da View"
      ],
      "metadata": {
        "id": "7FKg23wY4eRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação das Views em SQL\n",
        "\n",
        "# Importe a biblioteca para SQL no ambiente do Google Colab\n",
        "from google.colab import sql\n",
        "sql_conn = sql.Connection()\n",
        "\n",
        "# View 1: Rota mais utilizada por companhia aérea\n",
        "view1_query = \"\"\"\n",
        "CREATE OR REPLACE VIEW RotaMaisUtilizada AS\n",
        "SELECT\n",
        "    c.RazaoSocial AS CompanhiaAerea,\n",
        "    a1.Nome AS AeroportoOrigem,\n",
        "    a1.ICAO AS ICAOOrigem,\n",
        "    a1.Estado AS EstadoOrigem,\n",
        "    a2.Nome AS AeroportoDestino,\n",
        "    a2.ICAO AS ICAODestino,\n",
        "    a2.Estado AS EstadoDestino\n",
        "FROM CompanhiasAereas c\n",
        "JOIN Voos v ON c.ID = v.CompanhiaAereaID\n",
        "JOIN Aeroportos a1 ON v.AeroportoOrigemID = a1.ID\n",
        "JOIN Aeroportos a2 ON v.AeroportoDestinoID = a2.ID\n",
        "GROUP BY c.RazaoSocial\n",
        "ORDER BY COUNT(*) DESC\n",
        "LIMIT 1;\n",
        "\"\"\"\n",
        "\n",
        "# View 2: Companhia aérea com maior atuação em um aeroporto por ano\n",
        "view2_query = \"\"\"\n",
        "CREATE OR REPLACE VIEW CompanhiaMaisAtuacao AS\n",
        "SELECT\n",
        "    a.Nome AS Aeroporto,\n",
        "    a.ICAO AS ICAOAeroporto,\n",
        "    c.RazaoSocial AS CompanhiaAerea,\n",
        "    COUNT(DISTINCT v1.ID) AS RotasSaindo,\n",
        "    COUNT(DISTINCT v2.ID) AS RotasChegando,\n",
        "    COUNT(*) AS TotalPousosDecolagens\n",
        "FROM Aeroportos a\n",
        "JOIN Voos v1 ON a.ID = v1.AeroportoOrigemID\n",
        "JOIN Voos v2 ON a.ID = v2.AeroportoDestinoID\n",
        "JOIN CompanhiasAereas c ON v1.CompanhiaAereaID = c.ID\n",
        "GROUP BY a.Nome, c.RazaoSocial\n",
        "HAVING COUNT(*) = (SELECT MAX(CountTotal) FROM\n",
        "    (SELECT a1.Nome AS AeroportoNome, c1.RazaoSocial AS CompanhiaNome, COUNT(*) AS CountTotal\n",
        "     FROM Aeroportos a1\n",
        "     JOIN Voos v1 ON a1.ID = v1.AeroportoOrigemID\n",
        "     JOIN CompanhiasAereas c1 ON v1.CompanhiaAereaID = c1.ID\n",
        "     GROUP BY a1.Nome, c1.RazaoSocial) t\n",
        "    WHERE t.AeroportoNome = a.Nome);\n",
        "\"\"\"\n",
        "\n",
        "# Execute as queries SQL no ambiente do Google Colab\n",
        "sql_conn.execute(view1_query)\n",
        "sql_conn.execute(view2_query)\n"
      ],
      "metadata": {
        "id": "Mv-zz1C24mWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Justificativas sobre Escalabilidade e Camadas\n"
      ],
      "metadata": {
        "id": "pxL9G0EtczsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  1.Escalabilidade de Tecnologia: A utilização de Python com bibliotecas como pandas e requests é escalável, pois essas bibliotecas são eficientes para manipular grandes volumes de dados. Além disso, a abordagem de normalização de dados e uso de SQL para criação de visualizações é escalável, pois permite o processamento eficiente de grandes conjuntos de dados.\n",
        "\n",
        "  2.Camadas de Ingestão de Dados: O processo de ingestão de dados é dividido em várias camadas, incluindo a camada de leitura de arquivos, normalização de dados, obtenção de informações de aeródromos e criação de visualizações. Essas camadas permitem uma organização modular e escalável do processo de ingestão, facilitando futuras expansões e manutenção. O uso de um banco de dados relacional também ajuda na organização dos dados e consultas eficientes.\n",
        "\n",
        "  3.Automatização: A automação do processo de ingestão, como agendar a execução regular do código, torna a solução escalável para lidar com dados que são atualizados regularmente."
      ],
      "metadata": {
        "id": "M6mbEkZNc3zV"
      }
    }
  ]
}